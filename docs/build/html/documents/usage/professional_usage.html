<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Professional Usage &mdash; XuanPolicy v0.1.11 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/fonts.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tabs.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Agents" href="../api/agents.html" />
    <link rel="prev" title="Quick Start" href="basic_usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            XuanPolicy
              <img src="../../_static/logo_2.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">How to use:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">Quick Start</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Professional Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#step-1-create-config-file">Step 1: Create config file</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-2-get-the-attributes-of-the-example">Step 2: Get the attributes of the example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-3-define-run-create-and-run-the-model">Step 3: Define run(), create and run the model</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/representations.html">Representations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/policies.html">Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/learners.html">Learners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/runners.html">Runners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/configs.html">Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/common.html">Common</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/environments.html">Environments</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/toy.html">Toy benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/mujoco.html">MuJoCo benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/atari.html">Atari benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/mpe.html">MPE benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/magent.html">Magent benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithms:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/index_drl.html">Deep Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/index_marl.html">Multi-Agent Reinforcement Learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">XuanPolicy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Professional Usage</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/documents/usage/professional_usage.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="professional-usage">
<h1>Professional Usage<a class="headerlink" href="#professional-usage" title="Permalink to this heading">¶</a></h1>
<p>The previous page demonstrated how to directly run an algorithm by calling the runner.
In order to help users better understand the internal implementation process of “XuanPolicy”,
and facilitate further algorithm development and implementation of their own reinforcement learning tasks,
this section will take the PPO algorithm training on the MuJoCo environment task as an example,
and provide a detailed introduction on how to call the API from the bottom level to implement reinforcement learning model training.</p>
<br><hr><section id="step-1-create-config-file">
<h2>Step 1: Create config file<a class="headerlink" href="#step-1-create-config-file" title="Permalink to this heading">¶</a></h2>
<p>A config file should contains the necessary arguments of a PPO agent, and should be a YAML file.
Here we show a config file named “mujoco.yaml” for MuJoCo environment in gym.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dl_toolbox</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;torch&quot;</span><span class="w">  </span><span class="c1"># The deep learning toolbox. Choices: &quot;torch&quot;, &quot;mindspore&quot;, &quot;tensorlayer&quot;</span>
<span class="nt">project_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;XuanPolicy_Benchmark&quot;</span>
<span class="nt">logger</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;tensorboard&quot;</span><span class="w">  </span><span class="c1"># Choices: tensorboard, wandb.</span>
<span class="nt">wandb_user_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;your_user_name&quot;</span>
<span class="nt">render</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="nt">render_mode</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;rgb_array&#39;</span><span class="w"> </span><span class="c1"># Choices: &#39;human&#39;, &#39;rgb_array&#39;.</span>
<span class="nt">test_mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;cuda:0&quot;</span>

<span class="nt">agent</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;PPO_Clip&quot;</span><span class="w">  </span><span class="c1"># choice: PPO_Clip, PPO_KL</span>
<span class="nt">env_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;MuJoCo&quot;</span>
<span class="nt">vectorize</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Dummy_Gym&quot;</span>
<span class="nt">runner</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;DRL&quot;</span>

<span class="nt">representation_hidden_size</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,]</span>
<span class="nt">actor_hidden_size</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,]</span>
<span class="nt">critic_hidden_size</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,]</span>
<span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;LeakyReLU&quot;</span>

<span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">79811</span>
<span class="nt">parallels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="nt">running_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000000</span>
<span class="nt">n_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="nt">n_epoch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="nt">n_minibatch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0004</span>

<span class="nt">use_grad_clip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>

<span class="nt">vf_coef</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.25</span>
<span class="nt">ent_coef</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="nt">target_kl</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span><span class="w">  </span><span class="c1"># for PPO_KL agent</span>
<span class="nt">clip_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span><span class="w">  </span><span class="c1"># for PPO_Clip agent</span>
<span class="nt">clip_grad_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="nt">gamma</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.99</span>
<span class="nt">use_gae</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="nt">gae_lambda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.95</span>
<span class="nt">use_advnorm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>

<span class="nt">use_obsnorm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="nt">use_rewnorm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="nt">obsnorm_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="nt">rewnorm_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>

<span class="nt">test_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span>
<span class="nt">eval_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5000</span>
<span class="nt">test_episode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="nt">log_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;./logs/ppo/&quot;</span>
<span class="nt">model_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;./models/ppo/&quot;</span>
</pre></div>
</div>
<br><hr></section>
<section id="step-2-get-the-attributes-of-the-example">
<h2>Step 2: Get the attributes of the example<a class="headerlink" href="#step-2-get-the-attributes-of-the-example" title="Permalink to this heading">¶</a></h2>
<p>This section mainly includes parameter reading, environment creation, model creation, and model training.
First, create a <cite>ppo_mujoco.py</cite> file. The code writing process can be divided into the following steps:</p>
<p><strong>Step 2.1 Get the hyper-parameters of command in console</strong></p>
<p>Define the following function <code class="docutils literal notranslate"><span class="pre">parse_args()</span></code>,
which uses the Python package <cite>argparser</cite> to read the command line instructions and obtain the instruction parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparser</span>

<span class="k">def</span> <span class="nf">parse_args</span><span class="p">():</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="s2">&quot;Example of XuanPolicy.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--method&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;ppo&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--env&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;mujoco&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--env-id&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;InvertedPendulum-v4&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--test&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--device&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--benchmark&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--config&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./ppo_mujoco_config.yaml&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Step 2.2 Get all attributes of the example</strong></p>
<p>First, the <code class="docutils literal notranslate"><span class="pre">parse_args()</span></code> function from Step 2.1 is called to read the command line instruction parameters,
and then the configuration parameters from Step 1 are obtained.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xuanpolicy</span> <span class="kn">import</span> <span class="n">get_arguments</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">get_arguments</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
                     <span class="n">env</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">env</span><span class="p">,</span>
                     <span class="n">env_id</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">env_id</span><span class="p">,</span>
                     <span class="n">config_path</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                     <span class="n">parser_args</span><span class="o">=</span><span class="n">parser</span><span class="p">)</span>
<span class="n">run</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<p>In this step, the <code class="docutils literal notranslate"><span class="pre">get_arguments()</span></code> function from “XuanPolicy” is called.
In this function, it first searches for readable parameters based on the combination of the <code class="docutils literal notranslate"><span class="pre">env</span></code> and <code class="docutils literal notranslate"><span class="pre">env_id</span></code> variables in the <cite>xuanpolicy/configs/</cite> directory.
If default parameters already exist, they are all read. Then, the function continues to index the configuration file from Step 1 using the <code class="docutils literal notranslate"><span class="pre">config.path</span></code> path and reads all the parameters from the .yaml file.
Finally, it reads all the parameters from the <code class="docutils literal notranslate"><span class="pre">parser</span></code>.</p>
<p>During the three reading processes, if there are duplicate variable names, the latter parameters will overwrite the former ones.
Ultimately, the <code class="docutils literal notranslate"><span class="pre">get_arguments()</span></code> function will return the <code class="docutils literal notranslate"><span class="pre">args</span></code> variable, which contains all the parameter information and is input into the <code class="docutils literal notranslate"><span class="pre">run()</span></code> function.</p>
<br><hr></section>
<section id="step-3-define-run-create-and-run-the-model">
<h2>Step 3: Define run(), create and run the model<a class="headerlink" href="#step-3-define-run-create-and-run-the-model" title="Permalink to this heading">¶</a></h2>
<p>Define the run() function with the input as the args variable obtained in Step 2.
In this function, environment creation is implemented, and modules such as representation, policy, and agent are instantiated to perform the training.</p>
<p>Here is an example definition of the run() function with comments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>

<span class="kn">from</span> <span class="nn">xuanpolicy.common</span> <span class="kn">import</span> <span class="n">space2shape</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.environment</span> <span class="kn">import</span> <span class="n">make_envs</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.torch.utils.operations</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.torch.utils</span> <span class="kn">import</span> <span class="n">ActivationFunctions</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">agent_name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">agent</span>  <span class="c1"># get the name of Agent.</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># set random seed.</span>

    <span class="c1"># prepare directories for results</span>
    <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">env_id</span><span class="p">)</span>  <span class="c1"># the path for saved model.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">env_id</span><span class="p">)</span>  <span class="c1"># the path for logger file.</span>

    <span class="c1"># build environments</span>
    <span class="n">envs</span> <span class="o">=</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># create simulation environments</span>
    <span class="n">args</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">observation_space</span>  <span class="c1"># get observation space</span>
    <span class="n">args</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">action_space</span>  <span class="c1"># get action space</span>
    <span class="n">n_envs</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">num_envs</span>  <span class="c1"># get the number of vectorized environments.</span>

    <span class="c1"># prepare representation</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.representations</span> <span class="kn">import</span> <span class="n">Basic_MLP</span>
    <span class="n">representation</span> <span class="o">=</span> <span class="n">Basic_MLP</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">space2shape</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">observation_space</span><span class="p">),</span>
                            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">representation_hidden_size</span><span class="p">,</span>
                            <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">initialize</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">ActivationFunctions</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">activation</span><span class="p">],</span>
                            <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># create representation</span>

    <span class="c1"># prepare policy</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.policies</span> <span class="kn">import</span> <span class="n">Gaussian_AC_Policy</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">Gaussian_AC_Policy</span><span class="p">(</span><span class="n">action_space</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
                                <span class="n">representation</span><span class="o">=</span><span class="n">representation</span><span class="p">,</span>
                                <span class="n">actor_hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">actor_hidden_size</span><span class="p">,</span>
                                <span class="n">critic_hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">critic_hidden_size</span><span class="p">,</span>
                                <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">initialize</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">ActivationFunctions</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">activation</span><span class="p">],</span>
                                <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># create Gaussian policy</span>

    <span class="c1"># prepare agent</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.agents</span> <span class="kn">import</span> <span class="n">PPOCLIP_Agent</span><span class="p">,</span> <span class="n">get_total_iters</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>  <span class="c1"># create optimizer</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LinearLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">start_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">end_factor</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                                    <span class="n">total_iters</span><span class="o">=</span><span class="n">get_total_iters</span><span class="p">(</span><span class="n">agent_name</span><span class="p">,</span> <span class="n">args</span><span class="p">))</span>  <span class="c1"># for learning rate decay</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">PPOCLIP_Agent</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                          <span class="n">envs</span><span class="o">=</span><span class="n">envs</span><span class="p">,</span>
                          <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                          <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                          <span class="n">scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># create a PPO agent</span>

    <span class="c1"># start running</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># reset the environments</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">benchmark</span><span class="p">:</span>  <span class="c1"># run benchmark</span>
        <span class="k">def</span> <span class="nf">env_fn</span><span class="p">():</span>  <span class="c1"># for creating testing environments</span>
            <span class="n">args_test</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="n">args_test</span><span class="o">.</span><span class="n">parallels</span> <span class="o">=</span> <span class="n">args_test</span><span class="o">.</span><span class="n">test_episode</span>  <span class="c1"># set number of testing environments.</span>
            <span class="k">return</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args_test</span><span class="p">)</span>  <span class="c1"># make testing environments.</span>

        <span class="n">train_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">running_steps</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># calculate the tutorial running steps.</span>
        <span class="n">eval_interval</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># calculate the number of training steps per epoch.</span>
        <span class="n">test_episode</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">test_episode</span>  <span class="c1"># calculate the number of testing episodes.</span>
        <span class="n">num_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_steps</span> <span class="o">/</span> <span class="n">eval_interval</span><span class="p">)</span>  <span class="c1"># calculate the number of epochs.</span>

        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># first test</span>
        <span class="n">best_scores_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>  <span class="c1"># average episode scores.</span>
                            <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>  <span class="c1"># the standard deviation of the episode scores.</span>
                            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">current_step</span><span class="p">}</span>  <span class="c1"># current step</span>
        <span class="k">for</span> <span class="n">i_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epoch</span><span class="p">):</span>  <span class="c1"># begin benchmarking</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i_epoch</span><span class="p">,</span> <span class="n">num_epoch</span><span class="p">))</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">eval_interval</span><span class="p">)</span>  <span class="c1"># train the model for some steps</span>
            <span class="n">test_scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># test the model for some episodes</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]:</span>  <span class="c1"># if current score is better than history</span>
                <span class="n">best_scores_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>
                                    <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>
                                    <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">current_step</span><span class="p">}</span>
                <span class="c1"># save best model</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;best_model.pth&quot;</span><span class="p">)</span>
        <span class="c1"># end benchmarking</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Model Score: </span><span class="si">%.2f</span><span class="s2">, std=</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;std&quot;</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">:</span>  <span class="c1"># train the model without testing</span>
            <span class="n">n_train_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">running_steps</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># calculate the tutorial steps of training</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_train_steps</span><span class="p">)</span>  <span class="c1"># train the model directly.</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;final_train_model.pth&quot;</span><span class="p">)</span>  <span class="c1"># save the final model file.</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish training!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># test a trained model</span>
            <span class="k">def</span> <span class="nf">env_fn</span><span class="p">():</span>
                <span class="n">args_test</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">args_test</span><span class="o">.</span><span class="n">parallels</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">return</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args_test</span><span class="p">)</span>

            <span class="n">agent</span><span class="o">.</span><span class="n">render</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">model_dir_load</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># load the model file</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># test the model</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="si">}</span><span class="s2">, Std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish testing.&quot;</span><span class="p">)</span>

    <span class="c1"># the end.</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>  <span class="c1"># close the environment</span>
    <span class="n">agent</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>  <span class="c1"># finish the example</span>
</pre></div>
</div>
<p>After finishing the above three steps, you can run the <cite>python_mujoco.py</cite> file in console and train the model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>ppo_mujoco.py<span class="w"> </span>--method<span class="w"> </span>ppo<span class="w"> </span>--env<span class="w"> </span>mujoco<span class="w"> </span>--env-id<span class="w"> </span>Ant-v4
</pre></div>
</div>
<p>The source code of this example can be visited at the following link:</p>
<p><a class="reference external" href="https://github.com/agi-brain/xuanpolicy/examples/ppo/ppo_mujoco.py/">https://github.com/agi-brain/xuanpolicy/examples/ppo/ppo_mujoco.py</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="basic_usage.html" class="btn btn-neutral float-left" title="Quick Start" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api/agents.html" class="btn btn-neutral float-right" title="Agents" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, XuanPolicy contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>