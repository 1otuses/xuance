# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
# 2.You can search the last `------------------------>` to the node which is inferred failed.
# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.dat to get more instructions.
# ===============================================================================

# [No.1] Default_wrapper.40
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:31/    def construct(self, *inputs):/
funcgraph fg_40(
        %para1 : Tensor(F32)[1280, 4]    # inputs0
        , %para2 : Tensor(F32)[1280]    # inputs1
        , %para3 : Tensor(F32)[1280]    # inputs2
        , %para4 : Tensor(F32)[1280]    # inputs3
        , %para5 : Ref[Tensor(F32)][256, 4]    # _backbone.representation.model.0.weight
        , %para6 : Ref[Tensor(F32)][256]    # _backbone.representation.model.0.bias
        , %para7 : Ref[Tensor(F32)][256, 256]    # _backbone.actor.model.0.weight
        , %para8 : Ref[Tensor(F32)][256]    # _backbone.actor.model.0.bias
        , %para9 : Ref[Tensor(F32)][2, 256]    # _backbone.actor.model.2.weight
        , %para10 : Ref[Tensor(F32)][2]    # _backbone.actor.model.2.bias
        , %para11 : Ref[Tensor(F32)][256, 256]    # _backbone.critic.model.0.weight
        , %para12 : Ref[Tensor(F32)][256]    # _backbone.critic.model.0.bias
        , %para13 : Ref[Tensor(F32)][1, 256]    # _backbone.critic.model.2.weight
        , %para14 : Ref[Tensor(F32)][1]    # _backbone.critic.model.2.bias
        , %para15 : Ref[Tensor(F32)][1]    # beta1_power
        , %para16 : Ref[Tensor(F32)][1]    # beta2_power
        , %para17 : Ref[Tensor(F32)][256, 4]    # moment1.representation.model.0.weight
        , %para18 : Ref[Tensor(F32)][256]    # moment1.representation.model.0.bias
        , %para19 : Ref[Tensor(F32)][256, 256]    # moment1.actor.model.0.weight
        , %para20 : Ref[Tensor(F32)][256]    # moment1.actor.model.0.bias
        , %para21 : Ref[Tensor(F32)][2, 256]    # moment1.actor.model.2.weight
        , %para22 : Ref[Tensor(F32)][2]    # moment1.actor.model.2.bias
        , %para23 : Ref[Tensor(F32)][256, 256]    # moment1.critic.model.0.weight
        , %para24 : Ref[Tensor(F32)][256]    # moment1.critic.model.0.bias
        , %para25 : Ref[Tensor(F32)][1, 256]    # moment1.critic.model.2.weight
        , %para26 : Ref[Tensor(F32)][1]    # moment1.critic.model.2.bias
        , %para27 : Ref[Tensor(F32)][256, 4]    # moment2.representation.model.0.weight
        , %para28 : Ref[Tensor(F32)][256]    # moment2.representation.model.0.bias
        , %para29 : Ref[Tensor(F32)][256, 256]    # moment2.actor.model.0.weight
        , %para30 : Ref[Tensor(F32)][256]    # moment2.actor.model.0.bias
        , %para31 : Ref[Tensor(F32)][2, 256]    # moment2.actor.model.2.weight
        , %para32 : Ref[Tensor(F32)][2]    # moment2.actor.model.2.bias
        , %para33 : Ref[Tensor(F32)][256, 256]    # moment2.critic.model.0.weight
        , %para34 : Ref[Tensor(F32)][256]    # moment2.critic.model.0.bias
        , %para35 : Ref[Tensor(F32)][1, 256]    # moment2.critic.model.2.weight
        , %para36 : Ref[Tensor(F32)][1]    # moment2.critic.model.2.bias
        , %para37 : Ref[Tensor(F32)][256, 4]    # vhat.representation.model.0.weight
        , %para38 : Ref[Tensor(F32)][256]    # vhat.representation.model.0.bias
        , %para39 : Ref[Tensor(F32)][256, 256]    # vhat.actor.model.0.weight
        , %para40 : Ref[Tensor(F32)][256]    # vhat.actor.model.0.bias
        , %para41 : Ref[Tensor(F32)][2, 256]    # vhat.actor.model.2.weight
        , %para42 : Ref[Tensor(F32)][2]    # vhat.actor.model.2.bias
        , %para43 : Ref[Tensor(F32)][256, 256]    # vhat.critic.model.0.weight
        , %para44 : Ref[Tensor(F32)][256]    # vhat.critic.model.0.bias
        , %para45 : Ref[Tensor(F32)][1, 256]    # vhat.critic.model.2.weight
        , %para46 : Ref[Tensor(F32)][1]    # vhat.critic.model.2.bias
        , %para47 : Ref[Tensor(I32)][1]    # global_step
    ) {
    %1 : Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)) = Primitive::MakeTuple{prim_type=1}(%para1, %para2, %para3, %para4)    #(Tensor(F32)[1280, 4], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1280]) #scope: Default
#[CNode]58

#------------------------> 0
    %2 = UnpackCall::unpack_call(FuncGraph::fg_59, %1)    #(FuncNoShape, Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)))    # fg_59=Default.59 #scope: Default
#[CNode]60
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]61
}
# order:
#   1: @Default_wrapper.40:[CNode]60{[0]: ValueNode<UnpackCall> unpack_call.62, [1]: ValueNode<FuncGraph> Default.59, [2]: [CNode]58}
#   2: @Default_wrapper.40:[CNode]61{[0]: ValueNode<Primitive> Return, [1]: [CNode]60}


# [No.2] UnpackCall.41

funcgraph fg_41(
        %para48 : FuncNoShape    # 42
        , %para49 : Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280))    # 43
    ) {
    %1 : Tensor(F32)[1280, 4] = Primitive::TupleGetItem{prim_type=1}(%para49, I64(0))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#63
    %2 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para49, I64(1))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#64
    %3 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para49, I64(2))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#65
    %4 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para49, I64(3))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#66

#------------------------> 1
    %5 = %para48(%1, %2, %3, %4)    #(Tensor(F32)[1280, 4], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1280]) #scope: Default
#67
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default
#68
}
# order:
#   1: @UnpackCall.41:67{[0]: 42, [1]: 63, [2]: 64, [3]: 65, [4]: 66}
#   2: @UnpackCall.41:68{[0]: ValueNode<Primitive> Return, [1]: 67}


# [No.3] Default.44
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:31/    def construct(self, *inputs):/
funcgraph fg_44[fg_40](
        %para50 : Tensor(F32)[1280, 4]    # inputs0
        , %para51 : Tensor(F32)[1280]    # inputs1
        , %para52 : Tensor(F32)[1280]    # inputs2
        , %para53 : Tensor(F32)[1280]    # inputs3
    ) {
    %1 : BoolNoShape = FuncGraph::fg_33(Bool(1))    #(BoolNoShape)    # fg_33=bool_.33 #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]69
    %2 : FuncNoShape = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_45, FuncGraph::fg_70)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_45=✓Default.45, fg_70=✗Default.70 #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]71

#------------------------> 2
    %3 = %2() #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]72
    %4 = FuncGraph::fg_73(%3)    #(Undefined)    # fg_73=↓Default.73 #scope: Default
#[CNode]74
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]75
}
# order:
#   1: @Default.44:фloss{[0]: ValueNode<UnpackCall> unpack_call.76, [1]: ValueNode<FuncGraph> ACNetWithLossCell.31, [2]: [CNode]77}
#   2: @Default.44:[CNode]78{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<FP32Imm> 1.000000}
#   3: @Default.44:[CNode]79{[0]: ValueNode<FuncGraph> tuple_to_array.80, [1]: [CNode]78}
#   4: @Default.44:[CNode]81{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: [CNode]79, [2]: ValueNode<Float> Float32}
#   5: @Default.44:[CNode]82{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]81}
#   6: @Default.44:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> ACNetWithLossCell.31, [2]: [CNode]77, [3]: [CNode]82}
#   7: @Default.44:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]83}
#   8: @Default.44:grads{[0]: ValueNode<UnpackCall> unpack_call.84, [1]: grads, [2]: [CNode]77, [3]: [CNode]82}
#   9: @Default.44:[CNode]69{[0]: ValueNode<FuncGraph> bool_.33, [1]: ValueNode<BoolImm> true}
#  10: @Default.44:[CNode]71{[0]: ValueNode<Primitive> Switch, [1]: [CNode]69, [2]: ValueNode<FuncGraph> ✓Default.45, [3]: ValueNode<FuncGraph> ✗Default.70}
#  11: @Default.44:[CNode]72{[0]: [CNode]71}
#  12: @Default.44:[CNode]74{[0]: ValueNode<FuncGraph> ↓Default.73, [1]: [CNode]72}
#  13: @Default.44:[CNode]75{[0]: ValueNode<Primitive> Return, [1]: [CNode]74}


# [No.4] ✓Default.45
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/
funcgraph fg_45[fg_44](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-clip_grad{prim_type=1}, I64(1), F32(0.5))    #(FuncNoShape, I64NoShape, F32NoShape) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:36/            grads = self.hyper_map(ms.ops.partial(clip_grad, self.clip_type, self.clip_value), grads)/#[CNode]85
    %2 : $(Default.44):Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)) = Primitive::MakeTuple{prim_type=1}(%para50, %para51, %para52, %para53)    #(Tensor(F32)[1280, 4], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1280]) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:31/    def construct(self, *inputs):/#[CNode]77
    %3 : $(Default.44):Tuple[F32]TupleShape(NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(F32(1))    #(F32NoShape) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#[CNode]78
    %4 : $(Default.44):Tensor(F32)[1] = FuncGraph::fg_80(%3)    #(Tuple[F32]TupleShape(NoShape))    # fg_80=tuple_to_array.80 #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#[CNode]79
    %5 : $(Default.44):Tensor(F32)[1] = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"], SrcT=F32, DstT=F32, dst_type=F32](%4, F32)    #(Tensor(F32)[1], TypeTypeNoShape) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#[CNode]81
    %6 : $(Default.44):Tuple[Tensor(F32)]TupleShape((1)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%5)    #(Tensor(F32)[1]) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#[CNode]82
    %7 : $(Default.44):FuncNoShape = UnpackGraphPrimitive::UnpackGraph{prim_type=1}(FuncGraph::fg_31, %2, %6)    #(FuncNoShape, Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), Tuple[Tensor(F32)]TupleShape((1)))    # fg_31=ACNetWithLossCell.31 #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %8 : $(Default.44):Tuple[Ref[Tensor(F32)]*10]TupleShape((256, 4), (256), (256, 256), (256), (2, 256), (2), (256, 256), (256), (1, 256), (1)) = Primitive::MakeTuple{prim_type=1}(%para5, %para6, %para7, %para8, %para9, %para10, %para11, %para12, %para13, %para14)    #(Ref[Tensor(F32)][256, 4], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256, 256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][2, 256], Ref[Tensor(F32)][2], Ref[Tensor(F32)][256, 256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][1, 256], Ref[Tensor(F32)][1]) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:32/        weights = self.weights/#[CNode]83
    %9 : $(Default.44):FuncNoShape = DoSignaturePrimitive::S-Prim-grad{prim_type=1}(%7, %8)    #(FuncNoShape, Tuple[Ref[Tensor(F32)]*10]TupleShape((256, 4), (256), (256, 256), (256), (2, 256), (2), (256, 256), (256), (1, 256), (1))) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads

#------------------------> 3
    %10 = $(Default.44):UnpackCall::unpack_call(%9, %2, %6)    #(FuncNoShape, Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), Tuple[Tensor(F32)]TupleShape((1))) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %11 = DoSignaturePrimitive::S-Prim-hyper_map{prim_type=1}(%1, %10)    #(Undefined, Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:36/            grads = self.hyper_map(ms.ops.partial(clip_grad, self.clip_type, self.clip_value), grads)/#grads
    Primitive::Return{prim_type=1}(%11)    #(Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:35/        if self.enable_clip_grad:/#[CNode]86
}
# order:
#   1: @✓Default.45:[CNode]85{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-clip_grad, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<FP32Imm> 0.500000}
#   2: @✓Default.45:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-hyper_map, [1]: [CNode]85, [2]: grads}
#   3: @✓Default.45:[CNode]86{[0]: ValueNode<Primitive> Return, [1]: grads}


# [No.5] UnpackCall.46

funcgraph fg_46(
        %para54 : FuncNoShape    # 47
        , %para55 : Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280))    # 48
        , %para56 : Tuple[Tensor(F32)]TupleShape((1))    # 49
    ) {
    %1 : Tensor(F32)[1280, 4] = Primitive::TupleGetItem{prim_type=1}(%para55, I64(0))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#87
    %2 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para55, I64(1))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#88
    %3 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para55, I64(2))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#89
    %4 : Tensor(F32)[1280] = Primitive::TupleGetItem{prim_type=1}(%para55, I64(3))    #(Tuple[Tensor(F32)*4]TupleShape((1280, 4), (1280), (1280), (1280)), I64NoShape) #scope: Default
#90
    %5 : Tensor(F32)[1] = Primitive::TupleGetItem{prim_type=1}(%para56, I64(0))    #(Tuple[Tensor(F32)]TupleShape((1)), I64NoShape) #scope: Default
#91

#------------------------> 4
    %6 = %para54(%1, %2, %3, %4, %5)    #(Tensor(F32)[1280, 4], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1]) #scope: Default
#92
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default
#93
}
# order:
#   1: @UnpackCall.46:92{[0]: 47, [1]: 87, [2]: 88, [3]: 89, [4]: 90, [5]: 91}
#   2: @UnpackCall.46:93{[0]: ValueNode<Primitive> Return, [1]: 92}


# [No.6] ACNetWithLossCell.50
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:14/        def construct(self, x, a, adv, r):/
funcgraph fg_50[fg_94](
        %para57 : Tensor(F32)[1280, 4]    # ACNetWithLossCell
        , %para58 : Tensor(F32)[1280]    # ACNetWithLossCell
        , %para59 : Tensor(F32)[1280]    # ACNetWithLossCell
        , %para60 : Tensor(F32)[1280]    # ACNetWithLossCell
        , %para61 : Tensor(F32)[1]    # ACNetWithLossCell
    ) {
    %1 : $(ACNetWithLossCell.94):FuncNoShape = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](%para-1)    #(FuncNoShape) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads

#------------------------> 5
    %2 = %1(%para57, %para58, %para59, %para60)    #(Tensor(F32)[1280, 4], Tensor(F32)[1280], Tensor(F32)[1280], Tensor(F32)[1280]) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %3 = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Undefined, Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %4 = %3(%para61)    #(Tensor(F32)[1]) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %5 = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Undefined, Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %6 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](MultitypeFuncGraph::env_get{(EnvType, Tensor)}, %5)    #(Undefined, Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    %7 = HyperMap::hyper_map(%6, %para-1)    #(Undefined, Tuple[Ref[Tensor(F32)]*10]TupleShape((256, 4), (256), (256, 256), (256), (2, 256), (2), (256, 256), (256), (1, 256), (1))) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/utils/set_trainer.py:34/        grads = self.grad(self.network, weights)(*inputs, self.cast(ms.ops.tuple_to_array((self.sens,)), ms.float32))/#grads
}
# order:
#   1: @ACNetWithLossCell.50:grads{[0]: grads, [1]: ACNetWithLossCell, [2]: ACNetWithLossCell, [3]: ACNetWithLossCell, [4]: ACNetWithLossCell}
#   2: ACNetWithLossCell{[0]: ValueNode<Primitive> TupleGetItem, [1]: ACNetWithLossCell, [2]: ValueNode<Int64Imm> 0}
#   3: @ACNetWithLossCell.50:grads{[0]: ValueNode<Primitive> TupleGetItem, [1]: grads, [2]: ValueNode<Int64Imm> 1}
#   4: @ACNetWithLossCell.50:grads{[0]: grads, [1]: ACNetWithLossCell}
#   5: @ACNetWithLossCell.50:grads{[0]: ValueNode<Primitive> TupleGetItem, [1]: grads, [2]: ValueNode<Int64Imm> 0}
#   6: @ACNetWithLossCell.50:grads{[0]: ValueNode<Primitive> Partial, [1]: ValueNode<MultitypeFuncGraph> env_get.95, [2]: grads}
#   7: @ACNetWithLossCell.50:grads{[0]: ValueNode<HyperMap> hyper_map.96, [1]: grads, [2]: 97}
#   8: @ACNetWithLossCell.50:grads{[0]: ValueNode<Primitive> Return, [1]: grads}


# [No.7] ACNetWithLossCell.31
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:14/        def construct(self, x, a, adv, r):/
funcgraph fg_31[fg_40](
        %para62 : Tensor(F32)[1280, 4]    # x
        , %para63 : Tensor(F32)[1280]    # a
        , %para64 : Tensor(F32)[1280]    # adv
        , %para65 : Tensor(F32)[1280]    # r
    ) {
    %1 : Tuple[String*2]TupleShape(NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("value", "probs")    #(StringNoShape, StringNoShape) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:16/            log_prob = self._backbone.actor.log_prob(value=a, probs=act_probs)/#[CNode]98
    %2 : Tuple[Dictionary[[state,],[Tensor[Float32]]],Tensor(F32)*2]TupleShape(NoShape, (1280, 2), (1280)) = FuncGraph::fg_99(%para62)    #(Tensor(F32)[1280, 4])    # fg_99=ActorCriticPolicy.99 #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:15/            _, act_probs, v_pred = self._backbone(x)/#[CNode]100
    %3 : Tensor(F32)[1280, 2] = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, I64(1))    #(Tuple[Dictionary[[state,],[Tensor[Float32]]],Tensor(F32)*2]TupleShape(NoShape, (1280, 2), (1280)), I64NoShape) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:15/            _, act_probs, v_pred = self._backbone(x)/#act_probs
    %4 : Tuple[Tensor(F32)*2]TupleShape((1280), (1280, 2)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%para63, %3)    #(Tensor(F32)[1280], Tensor(F32)[1280, 2]) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:16/            log_prob = self._backbone.actor.log_prob(value=a, probs=act_probs)/#[CNode]101
    %5 : Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%1, %4)    #(Tuple[String*2]TupleShape(NoShape, NoShape), Tuple[Tensor(F32)*2]TupleShape((1280), (1280, 2))) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:16/            log_prob = self._backbone.actor.log_prob(value=a, probs=act_probs)/#[CNode]102

#------------------------> 6
    %6 = UnpackCall::unpack_call(FuncGraph::fg_103, %5)    #(FuncNoShape, Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape)    # fg_103=LogProb.103 #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:16/            log_prob = self._backbone.actor.log_prob(value=a, probs=act_probs)/#log_prob
    %7 = DoSignaturePrimitive::S-Prim-mul{prim_type=1}(%para64, %6)    #(Tensor(F32)[1280], Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:17/            loss_a = -self._mean(adv * log_prob)/#[CNode]104
    %8 = DoSignaturePrimitive::S-Prim-ReduceMean{prim_type=1}[output_names=["y"], keep_dims=Bool(1), input_names=["input_x", "axis"]](%7)    #(Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:17/            loss_a = -self._mean(adv * log_prob)/#[CNode]105
    %9 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(%8)    #(Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:17/            loss_a = -self._mean(adv * log_prob)/#loss_a
    %10 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("probs")    #(Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:19/            loss_e = self._mean(self._backbone.actor.entropy(probs=act_probs))/#[CNode]106
    %11 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%3)    #(Tensor(F32)[1280, 2]) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:19/            loss_e = self._mean(self._backbone.actor.entropy(probs=act_probs))/#[CNode]107
    %12 = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%10, %11)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:19/            loss_e = self._mean(self._backbone.actor.entropy(probs=act_probs))/#[CNode]108
    %13 = UnpackCall::unpack_call(FuncGraph::fg_109, %12)    #(Undefined, Undefined)    # fg_109=Entropy.109 #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:19/            loss_e = self._mean(self._backbone.actor.entropy(probs=act_probs))/#[CNode]110
    %14 = DoSignaturePrimitive::S-Prim-ReduceMean{prim_type=1}[output_names=["y"], keep_dims=Bool(1), input_names=["input_x", "axis"]](%13)    #(Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:19/            loss_e = self._mean(self._backbone.actor.entropy(probs=act_probs))/#loss_e
    %15 = DoSignaturePrimitive::S-Prim-mul{prim_type=1}(F32(0.01), %14)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:20/            loss = loss_a - self._ent_coef * loss_e + self._vf_coef * loss_c/#[CNode]111
    %16 = DoSignaturePrimitive::S-Prim-sub{prim_type=1}(%9, %15)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:20/            loss = loss_a - self._ent_coef * loss_e + self._vf_coef * loss_c/#[CNode]112
    %17 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("logits", "labels")    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:18/            loss_c = self._loss_c(logits=v_pred, labels=r)/#[CNode]113
    %18 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, I64(2))    #(Tuple[Dictionary[[state,],[Tensor[Float32]]],Tensor(F32)*2]TupleShape(NoShape, (1280, 2), (1280)), Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:15/            _, act_probs, v_pred = self._backbone(x)/#v_pred
    %19 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%18, %para65)    #(Undefined, Tensor(F32)[1280]) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:18/            loss_c = self._loss_c(logits=v_pred, labels=r)/#[CNode]114
    %20 = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%17, %19)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:18/            loss_c = self._loss_c(logits=v_pred, labels=r)/#[CNode]115
    %21 = UnpackCall::unpack_call(FuncGraph::fg_116, %20)    #(Undefined, Undefined)    # fg_116=MSELoss.116 #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:18/            loss_c = self._loss_c(logits=v_pred, labels=r)/#loss_c
    %22 = DoSignaturePrimitive::S-Prim-mul{prim_type=1}(F32(0.25), %21)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:20/            loss = loss_a - self._ent_coef * loss_e + self._vf_coef * loss_c/#[CNode]117
    %23 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%16, %22)    #(Undefined, Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:20/            loss = loss_a - self._ent_coef * loss_e + self._vf_coef * loss_c/#loss
    Primitive::Return{prim_type=1}(%23)    #(Undefined) #scope: Default/network-ACNetWithLossCell
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/learners/policy_gradient/a2c_learner.py:22/            return loss/#[CNode]118
}
# order:
#   1: @ACNetWithLossCell.31:[CNode]100{[0]: ValueNode<FuncGraph> ActorCriticPolicy.99, [1]: x}
#   2: @ACNetWithLossCell.31:act_probs{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]100, [2]: ValueNode<Int64Imm> 1}
#   3: @ACNetWithLossCell.31:v_pred{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]100, [2]: ValueNode<Int64Imm> 2}
#   4: @ACNetWithLossCell.31:[CNode]98{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> value, [2]: ValueNode<StringImm> probs}
#   5: @ACNetWithLossCell.31:[CNode]101{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: a, [2]: act_probs}
#   6: @ACNetWithLossCell.31:[CNode]102{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]98, [2]: [CNode]101}
#   7: @ACNetWithLossCell.31:log_prob{[0]: ValueNode<UnpackCall> unpack_call.119, [1]: ValueNode<FuncGraph> LogProb.103, [2]: [CNode]102}
#   8: @ACNetWithLossCell.31:[CNode]104{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: adv, [2]: log_prob}
#   9: @ACNetWithLossCell.31:[CNode]105{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceMean, [1]: [CNode]104}
#  10: @ACNetWithLossCell.31:loss_a{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: [CNode]105}
#  11: @ACNetWithLossCell.31:[CNode]113{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> logits, [2]: ValueNode<StringImm> labels}
#  12: @ACNetWithLossCell.31:[CNode]114{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: v_pred, [2]: r}
#  13: @ACNetWithLossCell.31:[CNode]115{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]113, [2]: [CNode]114}
#  14: @ACNetWithLossCell.31:loss_c{[0]: ValueNode<UnpackCall> unpack_call.120, [1]: ValueNode<FuncGraph> MSELoss.116, [2]: [CNode]115}
#  15: @ACNetWithLossCell.31:[CNode]106{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> probs}
#  16: @ACNetWithLossCell.31:[CNode]107{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: act_probs}
#  17: @ACNetWithLossCell.31:[CNode]108{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]106, [2]: [CNode]107}
#  18: @ACNetWithLossCell.31:[CNode]110{[0]: ValueNode<UnpackCall> unpack_call.121, [1]: ValueNode<FuncGraph> Entropy.109, [2]: [CNode]108}
#  19: @ACNetWithLossCell.31:loss_e{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceMean, [1]: [CNode]110}
#  20: @ACNetWithLossCell.31:[CNode]111{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: ValueNode<FP32Imm> 0.010000, [2]: loss_e}
#  21: @ACNetWithLossCell.31:[CNode]112{[0]: ValueNode<DoSignaturePrimitive> S-Prim-sub, [1]: loss_a, [2]: [CNode]111}
#  22: @ACNetWithLossCell.31:[CNode]117{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: ValueNode<FP32Imm> 0.250000, [2]: loss_c}
#  23: @ACNetWithLossCell.31:loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: [CNode]112, [2]: [CNode]117}
#  24: @ACNetWithLossCell.31:[CNode]118{[0]: ValueNode<Primitive> Return, [1]: loss}


# [No.8] UnpackCall.51

funcgraph fg_51(
        %para66 : FuncNoShape    # 52
        , %para67 : Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape    # 53
    ) {
    %1 : Tensor(F32)[1280] = Primitive::dict_getitem{prim_type=1}(%para67, "value")    #(Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape, StringNoShape) #scope: Default/network-ACNetWithLossCell
#122
    %2 : Keyword[key : valuevalue : Tensor[Float32]]NoShape = Primitive::make_keyword_arg{prim_type=1}("value", %1)    #(StringNoShape, Tensor(F32)[1280]) #scope: Default/network-ACNetWithLossCell
#123
    %3 : Tensor(F32)[1280, 2] = Primitive::dict_getitem{prim_type=1}(%para67, "probs")    #(Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape, StringNoShape) #scope: Default/network-ACNetWithLossCell
#124
    %4 : Keyword[key : probsvalue : Tensor[Float32]]NoShape = Primitive::make_keyword_arg{prim_type=1}("probs", %3)    #(StringNoShape, Tensor(F32)[1280, 2]) #scope: Default/network-ACNetWithLossCell
#125

#------------------------> 7
    %5 = %para66(%2, %4)    #(Keyword[key : valuevalue : Tensor[Float32]]NoShape, Keyword[key : probsvalue : Tensor[Float32]]NoShape) #scope: Default/network-ACNetWithLossCell
#126
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-ACNetWithLossCell
#127
}
# order:
#   1: @UnpackCall.51:126{[0]: 52, [1]: 123, [2]: 125}
#   2: @UnpackCall.51:127{[0]: ValueNode<Primitive> Return, [1]: 126}


# [No.9] LogProb.54
# In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:21/        def construct(self, value, probs):/
funcgraph fg_54(
        %para68 : Keyword[key : valuevalue : Tensor[Float32]]NoShape    # value
        , %para69 : Keyword[key : probsvalue : Tensor[Float32]]NoShape    # probs
    ) {
    %1 : Tuple[String*2]TupleShape(NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("value", "probs")    #(StringNoShape, StringNoShape) #scope: Default/actor-ActorNet/log_prob-LogProb
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:22/            return self._dist.log_prob(value=value, probs=probs)/#[CNode]128
    %2 : Tensor(F32)[1280] = Primitive::extract_keyword_arg{prim_type=1}("value", %para68)    #(StringNoShape, Keyword[key : valuevalue : Tensor[Float32]]NoShape) #scope: Default
#[CNode]129
    %3 : Tensor(F32)[1280, 2] = Primitive::extract_keyword_arg{prim_type=1}("probs", %para69)    #(StringNoShape, Keyword[key : probsvalue : Tensor[Float32]]NoShape) #scope: Default
#[CNode]130
    %4 : Tuple[Tensor(F32)*2]TupleShape((1280), (1280, 2)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%2, %3)    #(Tensor(F32)[1280], Tensor(F32)[1280, 2]) #scope: Default/actor-ActorNet/log_prob-LogProb
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:22/            return self._dist.log_prob(value=value, probs=probs)/#[CNode]131
    %5 : Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%1, %4)    #(Tuple[String*2]TupleShape(NoShape, NoShape), Tuple[Tensor(F32)*2]TupleShape((1280), (1280, 2))) #scope: Default/actor-ActorNet/log_prob-LogProb
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:22/            return self._dist.log_prob(value=value, probs=probs)/#[CNode]132

#------------------------> 8
    %6 = UnpackCall::unpack_call(FuncGraph::fg_39, %5)    #(FuncNoShape, Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape)    # fg_39=log_prob.39 #scope: Default/actor-ActorNet/log_prob-LogProb
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:22/            return self._dist.log_prob(value=value, probs=probs)/#[CNode]133
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/actor-ActorNet/log_prob-LogProb
      # In file /home/wzliu/PCNL_XuanCe/XuanPolicy_Library/xuance/xuance/mindspore/policies/categorical.py:22/            return self._dist.log_prob(value=value, probs=probs)/#[CNode]134
}
# order:
#   1: @LogProb.54:[CNode]128{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> value, [2]: ValueNode<StringImm> probs}
#   2: @LogProb.54:[CNode]131{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]129, [2]: [CNode]130}
#   3: @LogProb.54:[CNode]132{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]128, [2]: [CNode]131}
#   4: @LogProb.54:[CNode]133{[0]: ValueNode<UnpackCall> unpack_call.135, [1]: ValueNode<FuncGraph> log_prob.39, [2]: [CNode]132}
#   5: @LogProb.54:[CNode]134{[0]: ValueNode<Primitive> Return, [1]: [CNode]133}


# [No.10] UnpackCall.55

funcgraph fg_55(
        %para70 : FuncNoShape    # 56
        , %para71 : Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape    # 57
    ) {
    %1 : Tensor(F32)[1280] = Primitive::dict_getitem{prim_type=1}(%para71, "value")    #(Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape, StringNoShape) #scope: Default/actor-ActorNet/log_prob-LogProb
#136
    %2 : Keyword[key : valuevalue : Tensor[Float32]]NoShape = Primitive::make_keyword_arg{prim_type=1}("value", %1)    #(StringNoShape, Tensor(F32)[1280]) #scope: Default/actor-ActorNet/log_prob-LogProb
#137
    %3 : Tensor(F32)[1280, 2] = Primitive::dict_getitem{prim_type=1}(%para71, "probs")    #(Dictionary[[value,probs,],[Tensor[Float32]*2]]NoShape, StringNoShape) #scope: Default/actor-ActorNet/log_prob-LogProb
#138
    %4 : Keyword[key : probsvalue : Tensor[Float32]]NoShape = Primitive::make_keyword_arg{prim_type=1}("probs", %3)    #(StringNoShape, Tensor(F32)[1280, 2]) #scope: Default/actor-ActorNet/log_prob-LogProb
#139

#------------------------> 9
    %5 = %para70(%2, %4)    #(Keyword[key : valuevalue : Tensor[Float32]]NoShape, Keyword[key : probsvalue : Tensor[Float32]]NoShape) #scope: Default/actor-ActorNet/log_prob-LogProb
#140
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/actor-ActorNet/log_prob-LogProb
#141
}
# order:
#   1: @UnpackCall.55:140{[0]: 56, [1]: 137, [2]: 139}
#   2: @UnpackCall.55:141{[0]: ValueNode<Primitive> Return, [1]: 140}


#===============================================================================
# num of function graphs in stack: 10
